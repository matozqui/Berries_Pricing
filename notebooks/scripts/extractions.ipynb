{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599759509405",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(crop,ctry,trade_ctry,ctgr):\n",
    "\n",
    "    ##  Function to get prices available    ##\n",
    "    \n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import transformations as transf\n",
    "    import extractions as extract\n",
    "    import config\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "\n",
    "    connStr = pyodbc.connect(config.db_con)\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT [Product],[Country],[Trade_Country],[Category],[Date_price],[Campaign],AVG([Price]) as [Price] FROM [Prices].[dbo].[prices] WHERE [Product] = '{crop}' AND [Country] = '{ctry}' AND [Trade_Country] = '{trade_ctry}' AND [Category] = '{ctgr}' GROUP BY [Product],[Country],[Trade_Country],[Category],[Date_price],[Campaign]\"\n",
    "    df_prices = pd.read_sql(qry, connStr)\n",
    "\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_interpolated(crop,ctry,trade_ctry,ctgr):\n",
    "    \n",
    "    ##  Function to get all prices interpolated weekly and mean, removing the first campaign available  ##\n",
    "\n",
    "    df_prices = get_prices(crop,ctry,trade_ctry,ctgr)\n",
    "    df_prices = df_prices[df_prices.Campaign > min(df_prices.Campaign)][['Date_price', 'Price']]\n",
    "    df_prices.set_index('Date_price',inplace=True)\n",
    "    df_prices.sort_index(inplace=True)\n",
    "    df_prices.index = df_prices.index.astype('datetime64[ns]') \n",
    "    df_prices = df_prices.resample('W-MON').mean()\n",
    "    rows_null = df_prices.isnull()\n",
    "    idx_null = rows_null[rows_null.any(axis=1)].index\n",
    "    df_prices_all = df_prices.interpolate()\n",
    "\n",
    "    return df_prices_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_prices(crop,ctry,trade_ctry,ctgr):\n",
    "    \n",
    "    ##  Function to get weeks without prices informed -no campaign period-  ##\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    df_prices = get_prices(crop,ctry,trade_ctry,ctgr)\n",
    "    df_prices = df_prices[df_prices.Campaign > min(df_prices.Campaign)][['Date_price', 'Price']]\n",
    "    df_prices.set_index('Date_price',inplace=True)\n",
    "    df_prices.sort_index(inplace=True)\n",
    "    df_prices.index = df_prices.index.astype('datetime64[ns]') \n",
    "    df_prices = df_prices.resample('W-MON').mean()\n",
    "    rows_null = df_prices.isnull()\n",
    "    idx_null = rows_null[rows_null.any(axis=1)].index\n",
    "    df_prices_all = df_prices.interpolate()\n",
    "\n",
    "    df_prices_non_zero = df_prices_all[~df_prices_all.index.isin(idx_null)]\n",
    "    listIndex = list(zip(df_prices_all.index, range(0,len(df_prices_all))))     # save all indexes in tuples list (index, idPosition)\n",
    "    listNull = idx_null     # save all null indexes\n",
    "\n",
    "    dfIndex = pd.DataFrame(listIndex)\n",
    "    dfNull = pd.DataFrame(listNull)\n",
    "    dfIndex.columns = ['Date_price','ID']\n",
    "    dfNullID = dfIndex.merge(dfNull, how='inner', on='Date_price')    # this dataframe contains the null indexes with their original index id\n",
    "\n",
    "    return dfNullID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volumes(crop,ctry,trade_ctry):\n",
    "\n",
    "    ##  Function to get UE volumes import from Spain (Agronometrics), weekly aggregated ##\n",
    "    \n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import transformations as transf\n",
    "    import extractions as extract\n",
    "    import config\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "    \n",
    "    connStr = pyodbc.connect(config.db_con)\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT * FROM [Prices].[dbo].[volumes] where cast([Country] as nvarchar) = cast('{ctry}' as nvarchar) and cast([Product] as nvarchar) = cast('{crop}' as nvarchar) and cast([Trade_Country] as nvarchar) = cast('{trade_ctry}' as nvarchar)\"\n",
    "\n",
    "    df_volumes = pd.read_sql(qry, connStr)\n",
    "\n",
    "    df_volumes = df_volumes[df_volumes.Campaign > min(df_volumes.Campaign)][['Date_volume', 'Volume']]\n",
    "    df_volumes.groupby('Date_volume').agg('sum')\n",
    "    df_volumes.set_index('Date_volume',inplace=True)\n",
    "    df_volumes.sort_index(inplace=True)\n",
    "    df_volumes.index = df_volumes.index.astype('datetime64[ns]') \n",
    "    df_volumes = df_volumes.resample('W-MON').sum()\n",
    "\n",
    "    return df_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labour():\n",
    "\n",
    "    ##  Function to get labor cost index evolution in Spain (https://www.mapa.gob.es)   ##\n",
    "\n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    import pandas as pd\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    import numpy as np\n",
    "    import paths\n",
    "\n",
    "    # May need to lag 1 year in order to allocate campaign costs to the actual fresh produce sales  \n",
    "    yr_adj = 1\n",
    "\n",
    "    # 1985-2017 file\n",
    "    df = pd.read_excel(paths.es_labour_file,sheet_name='IS',header=3,usecols = ['AÑO','Anual'])\n",
    "    df.AÑO = pd.to_datetime(df.AÑO, format='%Y')\n",
    "    df.rename(columns={'AÑO': 'year', 'Anual': 'labour_index'}, inplace=True)\n",
    "    df = df[(df.year.duplicated(keep='first')==False) & df.year.notnull()]\n",
    "    df.year = df.year.apply(lambda x : x + relativedelta(years=yr_adj))\n",
    "    df.set_index('year', inplace=True)\n",
    "    df_salaries = df\n",
    "\n",
    "    # 2018-2020 file\n",
    "    df = pd.read_excel(paths.es_labour_file2,sheet_name='IndSal2',header=3,usecols=['AÑO','Enero','Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiem.', 'Octubre', 'Noviem.', 'Diciem.'])\n",
    "    df.AÑO = pd.to_datetime(df.AÑO, format='%Y')\n",
    "    df.rename(columns={'AÑO': 'year'}, inplace=True)\n",
    "    df = df[(df.year.duplicated(keep='first')==False) & df.year.notnull()]\n",
    "    df.year = df.year.apply(lambda x : x + relativedelta(years=yr_adj))\n",
    "    df.set_index('year', inplace=True)\n",
    "    df = df.transpose().replace(0, np.NaN).mean(skipna=True).to_frame()\n",
    "    df.rename(columns={0: 'labour_index'}, inplace=True)\n",
    "\n",
    "    df_salaries = df_salaries.append(df)\n",
    "    df_salaries.index = df_salaries.index.astype('datetime64[ns]') \n",
    "    df_salaries = df_salaries.resample('W-MON').mean().fillna(method='ffill')\n",
    "\n",
    "    return df_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_state(crop,ctry,trade_ctry,ctgr):\n",
    "\n",
    "    ##  Function to get prices available    ##\n",
    "    \n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import transformations as transf\n",
    "    import extractions as extract\n",
    "    import config\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "\n",
    "    connStr = pyodbc.connect(config.db_con)\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT reg.[State], prices.[Product],prices.[Country],prices.[Trade_Country],prices.[Category],prices.[Date_price],prices.[Campaign],AVG([Price]) as [Price] FROM [Prices].[dbo].[prices] left join [Prices].[dbo].[regions] reg on reg.Region = prices.Region and reg.Country = prices.Country WHERE [Product] = '{crop}' AND prices.[Country] = '{ctry}' AND prices.[Trade_Country] = '{trade_ctry}' AND prices.[Category] = '{ctgr}' GROUP BY reg.[State], prices.[Product],prices.[Country],prices.[Trade_Country],prices.[Category],prices.[Date_price],prices.[Campaign]\"\n",
    "    df_prices = pd.read_sql(qry, connStr)\n",
    "\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volumes_state(crop,ctry,trade_ctry):\n",
    "\n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import transformations as transf\n",
    "    import extractions as extract\n",
    "    import config\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "\n",
    "    ##  Function to get UE volumes import from Spain (Agronometrics), weekly aggregated ##\n",
    "    \n",
    "    connStr = pyodbc.connect(config.db_con)\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT reg.[State], vols.[Product],vols.[Country],vols.[Trade_Country], vols.[Date_volume],vols.[Campaign],SUM([Volume]) as [Volume] FROM [Prices].[dbo].[volumes] vols left join [Prices].[dbo].[regions] reg on reg.Region = vols.Region and vols.Country = vols.Country where vols.[Country] = '{ctry}' and vols.[Product] = '{crop}' and vols.[Trade_Country] ='{trade_ctry}' group by reg.[State], vols.[Product],vols.[Country],vols.[Trade_Country], vols.[Date_volume],vols.[Campaign]\"\n",
    "\n",
    "    df_volumes = pd.read_sql(qry, connStr)\n",
    "\n",
    "    return df_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotting_analysis(df_prices, df_prices_full, desc):\n",
    "\n",
    "    # https://www.machinelearningplus.com/time-series/time-series-analysis-python/#:~:text=Time%20series%20is%20a%20sequence,in%20Python%20%E2%80%93%20A%20Comprehensive%20Guide.\n",
    "\n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import extractions as extract\n",
    "    import transformations as transf\n",
    "    import training as train\n",
    "    import import_data as imp\n",
    "    import inference as inf\n",
    "    import time  \n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    from datetime import date\n",
    "    import config as conf\n",
    "    import pandas as pd\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    from statsmodels.graphics.tsaplots import plot_acf\n",
    "    from statsmodels.tsa.stattools import pacf\n",
    "    from statsmodels.graphics.tsaplots import plot_pacf\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    import seaborn as sns\n",
    "\n",
    "    pp = PdfPages(f'../../data/02_intermediate/exloratory_analysis/{desc}.pdf')\n",
    "\n",
    "    df_prices['Week'] = df_prices.index.week\n",
    "    df_prices['Year'] = df_prices.index.year\n",
    "\n",
    "    # Evolution (line graph)\n",
    "    plot1 = plt.figure()\n",
    "    for i in list(df_prices.index.year.drop_duplicates()):\n",
    "        data_graph = df_prices[df_prices.index.year == i]\n",
    "        ax = sns.lineplot(x='Week',y='Price',data=data_graph, label=i)\n",
    "    plt.title('Evolution of market prices', fontsize=14)\n",
    "    plt.xlabel('Week', fontsize=10)\n",
    "    plt.ylabel('Producer Price (Local currency/Kg)', fontsize=10)\n",
    "    plt.savefig(f'../../data/02_intermediate/exloratory_analysis/{desc}_evolution.png')\n",
    "    pp.savefig(plot1)\n",
    "\n",
    "    # Distribution univariate kernel density estimate)\n",
    "    plot2 = plt.figure()\n",
    "    for i in list(df_prices.index.year.drop_duplicates()):\n",
    "        data_graph = df_prices[df_prices.index.year == i]\n",
    "        ax = sns.kdeplot(data_graph['Price'].dropna(),label=i, shade=True)\n",
    "    plt.title('Distribution market prices', fontsize=14)\n",
    "    plt.xlabel('Producer Price (Local currency/Kg)', fontsize=10)\n",
    "    plt.ylabel('Frequency', fontsize=10)\n",
    "    plt.savefig(f'../../data/02_intermediate/exloratory_analysis/{desc}_distribution.png')\n",
    "    pp.savefig(plot2)\n",
    "\n",
    "    # Boxplot for years\n",
    "    plot3 = plt.figure()\n",
    "    ax = sns.boxplot(x=\"Year\", y=\"Price\",data=df_prices, showmeans=True)\n",
    "    plt.title('Year-wise boxplot for market prices (trend)', fontsize=14)\n",
    "    plt.xlabel('Year', fontsize=10)\n",
    "    plt.ylabel('Producer Price (Local currency/Kg)', fontsize=10)\n",
    "    plt.savefig(f'../../data/02_intermediate/exloratory_analysis/{desc}_boxplot_years.png')\n",
    "    pp.savefig(plot3)\n",
    "\n",
    "    # Boxplot for weeks\n",
    "    plot4 = plt.figure(figsize=(14,6))\n",
    "    ax = sns.boxplot(x=\"Week\", y=\"Price\",data=df_prices, showmeans=True)\n",
    "    plt.title('Week-wise boxplot for market prices (seasonality)', fontsize=14)\n",
    "    plt.xlabel('Week', fontsize=1)\n",
    "    plt.ylabel('Producer Price (Local currency/Kg)', fontsize=10)\n",
    "    plt.savefig(f'../../data/02_intermediate/exloratory_analysis/{desc}_boxplot_weeks.png')\n",
    "    pp.savefig(plot4)\n",
    "\n",
    "    # ACF correlation\n",
    "    from statsmodels.graphics.tsaplots import plot_acf\n",
    "    acf(df_prices_full)\n",
    "    plot5 = plot_acf(df_prices_full,lags=100,unbiased=True)\n",
    "    plot5.savefig(f'../../data/02_intermediate/exloratory_analysis/{desc}_acf.png')\n",
    "    pp.savefig(plot5)\n",
    "    \n",
    "    from statsmodels.tsa.stattools import pacf\n",
    "    from statsmodels.graphics.tsaplots import plot_pacf\n",
    "    plot6 = plot_pacf(df_prices_full, lags = 30)\n",
    "    plot6.savefig(f'../../data/02_intermediate/exloratory_analysis/{desc}_pacf.png')\n",
    "    pp.savefig(plot6)\n",
    "\n",
    "    # Correlation between related campaign weeks\n",
    "    for y in range(2017,2020):\n",
    "        c = df_prices_full[df_prices_full.index.year==y]['Price'].reset_index()['Price'][0:21].corr(df_prices_full[df_prices_full.index.year==y+1].reset_index()['Price'][0:21])\n",
    "        print(f'Correlations between campaigns {y} and {y+1}: {c}')\n",
    "\n",
    "\n",
    "    pp.close()"
   ]
  }
 ]
}