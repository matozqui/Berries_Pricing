{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598980103918",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(crop,ctry,trade_ctry,ctgr):\n",
    "\n",
    "    ##  Function to get prices available    ##\n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import transformations as transf\n",
    "    import extractions as extract\n",
    "    import config\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "\n",
    "    connStr = pyodbc.connect(config.db_con)\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT [Product],[Country],[Trade_Country],[Category],[Date_price],[Campaign],AVG([Price]) as [Price] FROM [Prices].[dbo].[prices] WHERE [Product] = '{crop}' AND [Country] = '{ctry}' AND [Trade_Country] = '{trade_ctry}' AND [Category] = '{ctgr}' GROUP BY [Product],[Country],[Trade_Country],[Category],[Date_price],[Campaign]\"\n",
    "    df_prices = pd.read_sql(qry, connStr)\n",
    "\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_interpolated(crop,ctry,trade_ctry,ctgr):\n",
    "    \n",
    "    ##  Function to get all prices interpolated weekly and mean, removing the first campaign available  ##\n",
    "\n",
    "    df_prices = get_prices(crop,ctry,trade_ctry,ctgr)\n",
    "    df_prices = df_prices[df_prices.Campaign > min(df_prices.Campaign)][['Date_price', 'Price']]\n",
    "    df_prices.set_index('Date_price',inplace=True)\n",
    "    df_prices.sort_index(inplace=True)\n",
    "    df_prices.index = df_prices.index.astype('datetime64[ns]') \n",
    "    df_prices = df_prices.resample('W-MON').mean()\n",
    "    rows_null = df_prices.isnull()\n",
    "    idx_null = rows_null[rows_null.any(axis=1)].index\n",
    "    df_prices_all = df_prices.interpolate()\n",
    "\n",
    "    return df_prices_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_prices(crop,ctry,trade_ctry,ctgr):\n",
    "    \n",
    "    ##  Function to get weeks without prices informed -no campaign period-  ##\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    df_prices = get_prices(crop,ctry,trade_ctry,ctgr)\n",
    "    df_prices = df_prices[df_prices.Campaign > min(df_prices.Campaign)][['Date_price', 'Price']]\n",
    "    df_prices.set_index('Date_price',inplace=True)\n",
    "    df_prices.sort_index(inplace=True)\n",
    "    df_prices.index = df_prices.index.astype('datetime64[ns]') \n",
    "    df_prices = df_prices.resample('W-MON').mean()\n",
    "    rows_null = df_prices.isnull()\n",
    "    idx_null = rows_null[rows_null.any(axis=1)].index\n",
    "    df_prices_all = df_prices.interpolate()\n",
    "\n",
    "    df_prices_non_zero = df_prices_all[~df_prices_all.index.isin(idx_null)]\n",
    "    listIndex = list(zip(df_prices_all.index, range(0,len(df_prices_all))))     # save all indexes in tuples list (index, idPosition)\n",
    "    listNull = idx_null     # save all null indexes\n",
    "\n",
    "    dfIndex = pd.DataFrame(listIndex)\n",
    "    dfNull = pd.DataFrame(listNull)\n",
    "    dfIndex.columns = ['Date_price','ID']\n",
    "    dfNullID = dfIndex.merge(dfNull, how='inner', on='Date_price')    # this dataframe contains the null indexes with their original index id\n",
    "\n",
    "    return dfNullID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volumes(crop,ctry,trade_ctry):\n",
    "\n",
    "    import pyodbc\n",
    "    import pandas as pd\n",
    "\n",
    "    ##  Function to get UE volumes import from Spain (Agronometrics), weekly aggregated ##\n",
    "    \n",
    "    connStr = pyodbc.connect('DRIVER={ODBC Driver 13 for SQL Server};SERVER=bipro02\\\\adminbi;DATABASE=Prices;Trusted_Connection=yes')\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT * FROM [Prices].[dbo].[volumes] where cast([Country] as nvarchar) = cast('{ctry}' as nvarchar) and cast([Product] as nvarchar) = cast('{crop}' as nvarchar) and cast([Trade_Country] as nvarchar) = cast('{trade_ctry}' as nvarchar)\"\n",
    "\n",
    "    df_volumes = pd.read_sql(qry, connStr)\n",
    "\n",
    "    df_volumes = df_volumes[df_volumes.Campaign > min(df_volumes.Campaign)][['Date_volume', 'Volume']]\n",
    "    df_volumes.groupby('Date_volume').agg('sum')\n",
    "    df_volumes.set_index('Date_volume',inplace=True)\n",
    "    df_volumes.sort_index(inplace=True)\n",
    "    df_volumes.index = df_volumes.index.astype('datetime64[ns]') \n",
    "    df_volumes = df_volumes.resample('W-MON').sum()\n",
    "\n",
    "    return df_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labour():\n",
    "\n",
    "    ##  Function to get labor cost index evolution in Spain (https://www.mapa.gob.es)   ##\n",
    "\n",
    "    import pandas as pd\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    import numpy as np\n",
    "\n",
    "    # May need to lag 1 year in order to allocate campaign costs to the actual fresh produce sales  \n",
    "    yr_adj = 1\n",
    "\n",
    "    # 1985-2017 file\n",
    "    df = pd.read_excel('../../data/01_raw/labor/indicesysalariosagrariosenero1985-diciembre2017_tcm30-539891.xlsx',sheet_name='IS',header=3,usecols = ['AÑO','Anual'])\n",
    "    df.AÑO = pd.to_datetime(df.AÑO, format='%Y')\n",
    "    df.rename(columns={'AÑO': 'year', 'Anual': 'labour_index'}, inplace=True)\n",
    "    df = df[(df.year.duplicated(keep='first')==False) & df.year.notnull()]\n",
    "    df.year = df.year.apply(lambda x : x + relativedelta(years=yr_adj))\n",
    "    df.set_index('year', inplace=True)\n",
    "    df_salaries = df\n",
    "\n",
    "    # 2018-2020 file\n",
    "    df = pd.read_excel('../../data/01_raw/labor/indicesysalariosagrariosenero2018-marzo2020_tcm30-541202.xlsx',sheet_name='IndSal2',header=3,usecols=['AÑO','Enero','Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiem.', 'Octubre', 'Noviem.', 'Diciem.'])\n",
    "    df.AÑO = pd.to_datetime(df.AÑO, format='%Y')\n",
    "    df.rename(columns={'AÑO': 'year'}, inplace=True)\n",
    "    df = df[(df.year.duplicated(keep='first')==False) & df.year.notnull()]\n",
    "    df.year = df.year.apply(lambda x : x + relativedelta(years=yr_adj))\n",
    "    df.set_index('year', inplace=True)\n",
    "    df = df.transpose().replace(0, np.NaN).mean(skipna=True).to_frame()\n",
    "    df.rename(columns={0: 'labour_index'}, inplace=True)\n",
    "\n",
    "    df_salaries = df_salaries.append(df)\n",
    "    df_salaries.index = df_salaries.index.astype('datetime64[ns]') \n",
    "    df_salaries = df_salaries.resample('W-MON').mean().fillna(method='ffill')\n",
    "\n",
    "    return df_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_state(crop,ctry,trade_ctry,ctgr):\n",
    "\n",
    "    ##  Function to get prices available    ##\n",
    "    import sys\n",
    "    sys.path.insert(0, '../../src')\n",
    "    sys.path.append('../../src/d00_utils')\n",
    "    sys.path.append('../../src/d01_data')\n",
    "    sys.path.append('../../src/d02_processing')\n",
    "    sys.path.append('../../src/d03_modelling')\n",
    "    import transformations as transf\n",
    "    import extractions as extract\n",
    "    import config\n",
    "    import pandas as pd\n",
    "    import pyodbc\n",
    "\n",
    "    connStr = pyodbc.connect(config.db_con)\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"select reg.[State], prices.[Product],prices.[Country],prices.[Trade_Country],prices.[Category],prices.[Date_price],prices.[Campaign],AVG([Price]) as [Price] FROM [Prices].[dbo].[prices] left join [Prices].[dbo].[regions] reg on reg.Region = prices.Region and reg.Country = prices.Country WHERE [Product] = '{crop}' AND prices.[Country] = '{ctry}' AND prices.[Trade_Country] = '{trade_ctry}' AND prices.[Category] = '{ctgr}' GROUP BY reg.[State], prices.[Product],prices.[Country],prices.[Trade_Country],prices.[Category],prices.[Date_price],prices.[Campaign]\"\n",
    "    df_prices = pd.read_sql(qry, connStr)\n",
    "\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volumes_state(crop,ctry,trade_ctry):\n",
    "\n",
    "    import pyodbc\n",
    "    import pandas as pd\n",
    "\n",
    "    ##  Function to get UE volumes import from Spain (Agronometrics), weekly aggregated ##\n",
    "    \n",
    "    connStr = pyodbc.connect('DRIVER={ODBC Driver 13 for SQL Server};SERVER=bipro02\\\\adminbi;DATABASE=Prices;Trusted_Connection=yes')\n",
    "    cursor = connStr.cursor()\n",
    "\n",
    "    qry = f\"SELECT reg.[State], vols.[Product],vols.[Country],vols.[Trade_Country], vols.[Date_volume],vols.[Campaign],SUM([Volume]) as [Volume] FROM [Prices].[dbo].[volumes] vols left join [Prices].[dbo].[regions] reg on reg.Region = vols.Region and vols.Country = vols.Country where vols.[Country] = '{ctry}' and vols.[Product] = '{crop}' and vols.[Trade_Country] ='{trade_ctry}' group by reg.[State], vols.[Product],vols.[Country],vols.[Trade_Country], vols.[Date_volume],vols.[Campaign]\"\n",
    "\n",
    "    df_volumes = pd.read_sql(qry, connStr)\n",
    "\n",
    "    return df_volumes"
   ]
  }
 ]
}